{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/pytorch-pretrained-bert/pytorch-pretrained-BERT', '/kaggle/input/pytorch-pretrained-bert/pytorch-pretrained-BERT', '', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/content', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/hub/combat-wombat-bias-in-toxicity/', '/content/hub/combat-wombat-bias-in-toxicity/', '/content/hub/combat-wombat-bias-in-toxicity/code']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/content/hub/combat-wombat-bias-in-toxicity/code')\n",
    "\n",
    "\n",
    "package_dir_a = \"/kaggle/input/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
    "sys.path.insert(0, package_dir_a)\n",
    "\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: command: Command not found\n",
      "python3 -m pip show apex || ([ -d /kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a ] && \\\n",
      "python3 -m pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a)\n",
      "\u001b[33mWARNING: Package(s) not found: apex\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:243: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-3wkrmgd6\n",
      "Created temporary directory: /tmp/pip-req-tracker-6ph5mwak\n",
      "Initialized build tracking at /tmp/pip-req-tracker-6ph5mwak\n",
      "Created build tracker: /tmp/pip-req-tracker-6ph5mwak\n",
      "Entered build tracker: /tmp/pip-req-tracker-6ph5mwak\n",
      "Created temporary directory: /tmp/pip-install-4jofifym\n",
      "Processing /kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
      "  Created temporary directory: /tmp/pip-req-build-v266viet\n",
      "  Added file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a to build tracker '/tmp/pip-req-tracker-6ph5mwak'\n",
      "    Running setup.py (path:/tmp/pip-req-build-v266viet/setup.py) egg_info for package from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
      "    Created temporary directory: /tmp/pip-pip-egg-info-iv6mzar5\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.5.0+cu101\n",
      "    running egg_info\n",
      "    creating /tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info\n",
      "    writing /tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file '/tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-iv6mzar5/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-v266viet has version 0.1, which satisfies requirement apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
      "  Removed apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a from build tracker '/tmp/pip-req-tracker-6ph5mwak'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-j_l8jhq1\n",
      "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-v266viet/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-v266viet/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-j_l8jhq1/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6/apex\n",
      "    torch.__version__  =  1.5.0+cu101\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.243\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    Pytorch binaries were compiled with Cuda 10.1\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    running build_ext\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:304: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "      warnings.warn(msg.format('we could not find ninja.'))\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         return tensors[0].type();\n",
      "                                ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/flatten_unflatten.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n"
     ]
    }
   ],
   "source": [
    "!make apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertForSequenceClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toxic.utils import (\n",
    "    perfect_bias,\n",
    "    TensorboardAggregator,\n",
    "    clip_to_max_len,\n",
    "    should_decay,\n",
    ")\n",
    "from toxic.metrics import IDENTITY_COLUMNS\n",
    "from toxic.bert import PipeLineConfig, convert_line_gpt, AUX_TARGETS\n",
    "from toxic.utils import seed_everything, convert_dataframe_to_bool\n",
    "from toxic.blocks.nn import GPT2CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ACCUM_STEPS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt(config: PipeLineConfig):\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    logging.info(\"Reading data...\")\n",
    "    input_folder = \"../input/jigsaw-unintended-bias-in-toxicity-classification/\"\n",
    "    train = pd.read_csv(os.path.join(input_folder, \"train.csv\"))\n",
    "\n",
    "    logging.info(\"Reading wiki PL...\")\n",
    "    wiki_sents = pd.read_csv(\"../input/wiki_sents.csv\")\n",
    "    wiki_subset = wiki_sents[\n",
    "        (wiki_sents.target < 0.1) & (wiki_sents[IDENTITY_COLUMNS].max(1) >= 0.33)\n",
    "    ].copy()\n",
    "    wiki_subset.drop(\n",
    "        columns=[\"any_identity\", \"max_identity\", \"target_aux\"], inplace=True\n",
    "    )\n",
    "    wiki_subset.iloc[:, :6] = 0.0  # They are not toxic by definition\n",
    "\n",
    "    logging.info(\"Sampling extra data...\")\n",
    "    seed_everything(config.seed + 1)\n",
    "    extras = []\n",
    "    t = convert_dataframe_to_bool(train)\n",
    "\n",
    "    for identity in IDENTITY_COLUMNS:\n",
    "        Ip = np.sum(t[identity] & t.target)\n",
    "        I = np.sum(t[identity])\n",
    "        Bp = np.sum(~t[identity] & t.target)\n",
    "        B = np.sum(~t[identity])\n",
    "        required = (Ip * B - Bp * I) // Bp\n",
    "\n",
    "        extra = wiki_subset[wiki_subset[identity] >= 0.333].copy()\n",
    "        logging.info(\"Mitigating bias for %s\", identity)\n",
    "        logging.info(\"Need %d extra samples, got %d\", required, len(extra))\n",
    "\n",
    "        if len(extra) > required:\n",
    "            logging.info(\"Downsampling extra dataframe\")\n",
    "            extra = extra.sample(required)\n",
    "        extras.append(extra)\n",
    "\n",
    "    enriched = pd.concat([train] + extras, ignore_index=True, sort=False, axis=0)\n",
    "\n",
    "    logging.info(\"Tokenizing...\")\n",
    "\n",
    "    with multiprocessing.Pool(processes=32) as pool:\n",
    "        text_list = enriched.comment_text.tolist()\n",
    "        sequences = pool.map(convert_line_gpt, text_list)\n",
    "\n",
    "    logging.info(\"Building ttensors for training...\")\n",
    "    sequences = np.array(sequences)\n",
    "    print(sequences.shape)\n",
    "    lengths = np.argmax(sequences == 0, axis=1)\n",
    "    lengths[lengths == 0] = sequences.shape[1]\n",
    "\n",
    "    logging.info(\"Bulding target tesnor...\")\n",
    "    iden = enriched[IDENTITY_COLUMNS].fillna(0).values\n",
    "    subgroup_target = np.hstack(\n",
    "        [\n",
    "            (iden >= 0.5).any(axis=1, keepdims=True).astype(np.int),\n",
    "            iden,\n",
    "            iden.max(axis=1, keepdims=True),\n",
    "        ]\n",
    "    )\n",
    "    sub_target_weigths = (\n",
    "        ~enriched[IDENTITY_COLUMNS].isna().values.any(axis=1, keepdims=True)\n",
    "    ).astype(np.int)\n",
    "\n",
    "    weights = np.ones(len(enriched))\n",
    "    weights += (iden >= 0.5).any(1)\n",
    "    weights += (enriched[\"target\"].values >= 0.5) & (iden < 0.5).any(1)\n",
    "    weights += (enriched[\"target\"].values < 0.5) & (iden >= 0.5).any(1)\n",
    "    weights /= weights.mean()\n",
    "\n",
    "    y_aux_train = enriched[AUX_TARGETS]\n",
    "    y_train_torch = torch.tensor(\n",
    "        np.hstack(\n",
    "            [\n",
    "                enriched.target.values[:, None],\n",
    "                weights[:, None],\n",
    "                y_aux_train,\n",
    "                subgroup_target,\n",
    "                sub_target_weigths,\n",
    "            ]\n",
    "        )\n",
    "    ).float()\n",
    "\n",
    "    logging.info(\"Seeding with seed %d ...\", config.seed)\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    logging.info(\"Creating dataset...\")\n",
    "    dataset = data.TensorDataset(\n",
    "        torch.tensor(sequences), y_train_torch, torch.tensor(lengths)\n",
    "    )\n",
    "    train_loader = data.DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE, collate_fn=clip_to_max_len, shuffle=True\n",
    "    )\n",
    "\n",
    "    logging.info(\"Creating a model...\")\n",
    "    model = GPT2CNN.from_pretrained(\"gpt2\", num_labels=18)\n",
    "    model.zero_grad()\n",
    "    model = model.cuda()\n",
    "\n",
    "    logs_file = f\"./tb_logs/final_{config.expname}\"\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if should_decay(n)],\n",
    "            \"weight_decay\": config.decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not should_decay(n)],\n",
    "            \"weight_decay\": 0.00,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    optimizer = BertAdam(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=config.lr,\n",
    "        warmup=config.warmup,\n",
    "        t_total=config.epochs * len(train_loader) // ACCUM_STEPS,\n",
    "    )\n",
    "\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
    "    model = model.train()\n",
    "\n",
    "    writer = SummaryWriter(logs_file)\n",
    "    agg = TensorboardAggregator(writer)\n",
    "    custom_loss = prepare_loss(config)\n",
    "\n",
    "    for _ in range(config.epochs):\n",
    "        for j, (X, y) in enumerate(train_loader):\n",
    "\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = custom_loss(y_pred, y)\n",
    "\n",
    "            accuracy = ((y_pred[:, 0] > 0) == (y[:, 0] > 0.5)).float().mean()\n",
    "            agg.log({\"train_loss\": loss.item(), \"train_accuracy\": accuracy.item()})\n",
    "\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "\n",
    "            if (j + 1) % ACCUM_STEPS == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./models/final-pipe6-{config.expname}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config_1 = PipeLineConfig(\n",
    "        expname=\"gpt_wiki_1\",\n",
    "        lr=4.9e-5,\n",
    "        warmup=0.06,\n",
    "        epochs=2,\n",
    "        seed=50462,\n",
    "        decay=0.04,\n",
    "        main_loss_weight=1.05,\n",
    "    )\n",
    "    config_2 = PipeLineConfig(\n",
    "        expname=\"gpt_wiki_2\",\n",
    "        lr=4.7e-5,\n",
    "        warmup=0.055,\n",
    "        epochs=2,\n",
    "        seed=54184,\n",
    "        decay=0.06,\n",
    "        main_loss_weight=0.98,\n",
    "    )\n",
    "\n",
    "    for config in (config_1, config_2):\n",
    "        train_gpt(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
